# Chapter 6 - Analysis of longitudinal data

## RATS data

```{r, include=FALSE}
RATSL <- read.table("RATSL.txt")
BPRSL <- read.table("BPRSL.txt")
RATS <- read.table("https://raw.githubusercontent.com/KimmoVehkalahti/MABS/master/Examples/data/rats.txt", sep = "\t", header = T)

RATSL$ID <- as.factor(RATSL$ID)
RATSL$Group <- as.factor(RATSL$Group)

BPRSL$treatment <- as.factor(BPRSL$treatment)
BPRSL$subject <- as.factor(BPRSL$subject)
```

The RATS study is a nutritional study on rats. The rats were assigned into three groups with different diets, and their body weight was recorded approximately weekly (week 7 includes two recordings) up until week 9. The researchers wanted to explore whether the growth profiles differ between the groups. 

Let's take a look at the data.

```{r, message=FALSE}
library(dplyr);library(tidyr);library(ggplot2)

glimpse(RATSL)

ggplot(RATSL, aes(x = Time, y = Weight, linetype = ID)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  theme(legend.position = "none") + 
  scale_y_continuous(limits = c(min(RATSL$Weight), max(RATSL$Weight)))
```

The data frame has 5 columns and 176 rows. There are 16 rats in total, eight of them belong to group 1, four belong to group 2 and four to group 3. Rat ID is repeated due to weekly weight measurements. From the plot it seems Group 1 rats have had the lowest body weight throughout the study but groups 2 and 3 have had an increase. However, these rats also had more body weight to begin with. Group 2 has one rat whose body weight is high throughout the study, and group 3 as well as group 1 has a rat whose body weight is low compared to others in the group.

Let's standardise the weights and make a new plot.

```{r}
# Standardise weight
RATSL <- RATSL %>%
  group_by(Group) %>%
  mutate(stdweight=scale(Weight) ) %>%
  ungroup()

# Look at the new data
glimpse(RATSL)

# Plot the data
ggplot(RATSL, aes(x = Time, y = stdweight, linetype = ID)) +
  geom_line() +
  scale_linetype_manual(values = rep(1:10, times=4)) +
  facet_grid(. ~ Group, labeller = label_both) +
  scale_y_continuous(name = "standardized weight") +
  theme(legend.position = "none")
```

Now the weight increase looks similar in each group and the "outliers" mentioned before are now even more distinct.

Let's look at the mean weight profiles.

```{r}
# Extract number of measurement times
n <- RATSL$Time %>% unique() %>% length()

# Summary data with mean and standard error of weight by group and measurement times 
RATSS <- RATSL %>%
  group_by(Group, Time) %>%
  summarise(mean = mean(Weight), se = sd(Weight)/sqrt(n) ) %>%
  ungroup()

# Glimpse the data
glimpse(RATSS)

# Plot the mean profiles with standard error
ggplot(RATSS, aes(x = Time, y = mean, linetype = Group, shape = Group)) +
  geom_line() +
  geom_point(size=3) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se, linetype="1"), width=0.3) +
  theme(legend.position = c(0.8,0.8)) +
  scale_y_continuous(name = "mean(Weight) +/- se(Weight)") +
  theme(legend.position = "right")

```

There deos seem to be some more increase in weight in groups 2 and 3. Group 2 has a larger standard error than group 3. Group 1 has the lowest standard error.

Let's see if there are still outliers after averaging weight.

```{r, message = FALSE}
# Create a summary data by group and ID with mean as the summary variable.
RATSL8S <- RATSL %>%
  group_by(Group, ID) %>%
  summarise(mean=mean(Weight) ) %>%
  ungroup()

# Glimpse the data
glimpse(RATSL8S)

# Draw a boxplot of the mean versus group
ggplot(RATSL8S, aes(x = Group, y = mean)) +
  geom_boxplot() +
  stat_summary(fun.y = "mean", geom = "point", shape=23, size=4, fill = "white") +
  scale_y_continuous(name = "mean(Weight)")
```

From this plot we see there's one actual outlier in group 1, which is the lowest datapoint. Group 2 and 3 seem to have outliers BUT we only have four(!) rats in these groups. The amount is ridiculously small that it's dangerous to take anything out. Group 1 has 8 rats, so taking one out would still be feasible... But truth be told the whole research setting of one group having twice the amount of rats compared to other groups is not good. For the sake of my sanity I'd rather take four rats out of group 1 to make the groups more comparable. One of the excluded rats will be the outlier.

```{r}
RATSL_exc <- RATSL8S %>%
  filter(ID != 1, ID != 2, ID != 3, ID != 4) %>%
  group_by(mean) %>%
  ungroup()

glimpse(RATSL_exc)
```

Let's perform a t-test for this dataset. T-test requires two sets at a time, so we'll subset the data to suit thit test.

```{r}
# Subsetting for t-tests
test1 <- RATSL_exc %>% filter(Group != 1)
test2 <- RATSL_exc %>% filter(Group != 2)
test3 <- RATSL_exc %>% filter(Group != 3)

# Two-sample t-tests
t.test(mean ~ Group, data = test1, var.equal = TRUE)
t.test(mean ~ Group, data = test2, var.equal = TRUE)
t.test(mean ~ Group, data = test3, var.equal = TRUE)
```

The results are not significant between groups 2 and 3. The results are significant when comparing groups 1 against group 2 or group 3. The confidence interval includes 0 when comparing groups 2 and 3 but not when comparing group 1 against group 2 and 3, so we can reject the null hypothesis with 95 % certainty in the latter case.

Before we'll fit the linear model, we'll add a baseline to the data.
```{r}
# Add the baseline from the original data as a new variable to the summary data
RATS_filtered <- RATS %>% filter(ID != 1, ID != 2, ID != 3, ID != 4)

RATSL_exc <- RATSL_exc %>%
  mutate(baseline = RATS_filtered$WD1)

# Fit the linear model with the mean as the response 
fit <- lm(mean ~ baseline + Group, data = RATSL_exc)

# Compute the analysis of variance table for the fitted model with anova()
anova(fit)

```
ANOVA indicates there's no significant difference in the groups in their weight gain compared to their baselines. 

To summarise:
The results are in weight gain are significant if comparing groups 2 and 3 to group 1 (t-test) but within group difference is negligible (ANOVA).


## BPRS data

In this study we have 40 men who were randomly assigned into two treatment groups and their progress was monitored with brief psychiatric rating scale (BPRS). The measurements were made before treatment (week 0) up until week 8. BPRS assesses symptom constructs (e.g. hostility, hallucinations) and they are rated from one to seven (1 = not present, 7 = extremely severe).

We'll take a look at the dataset

```{r}
glimpse(BPRSL)

ggplot(BPRSL, aes(x = week, y = bprs, group = subject)) +
  geom_line(aes(linetype=subject)) + facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name= "Weeks") + scale_y_continuous(name = "BPRS points") + theme(legend.position = "top") +
  theme(legend.position = "none")
```

We see the two treatment groups look fairly similar. Treatment group 2 has one outlier subject whose BPRS score is high most of the time.

We'll fit two models. Both are random intercept and random slope models, the first is without interaction and second with interaction. Well see the effect of weeks and treatments and their interaction to BPRS scores. Additionally, we'll take each subject into account as a random effect.

```{r, message = FALSE, warning = FALSE}
library(lme4)

# Fitting the models
BPRS_model1 <- lmer(bprs ~ week + treatment + (weeks | subject), data = BPRSL)

# With interaction
BPRS_model2 <- lmer(bprs ~ week * treatment + (weeks | subject), data = BPRSL)

# Model summaries
summary(BPRS_model1)
summary(BPRS_model2)
```

The slope for week is negative in the non-interaction model, suggesting that the BPRS scores go down with time. Treatment group 2 seems to have slightly higher BPRS scores compared to treatment group 1. The slopes are negative for week and treatment 2 in the interaction model, suggesting that treatment group 2 has lower BPRS scores than treatment group 1. However, the interaction between week and treatment does not indicate the same. We were right to add subject as a random effect, since subject variance is high in both models.

```{r, message = FALSE, warning = FALSE}
# Comparison of the models with ANOVA
anova(BPRS_model1, BPRS_model2)
```
According to the ANOVA test model 2 has slightly smaller AIC value but slightly bigger BIC value than model 1, and the likelihood ratio test of model 1 against model 2 gives a chi-squared statistic of 3.33 with 1 degree of freedom (Df). The p value is not statistically significant (> 0.05). These results do not clearly indicate which model is a better fit for our data.

Either way it seems there are no statistically significant differences between the treatment groups.

We'll create new plots with fitted values from both of these models and compare them to the actual values, even though we can't say the models are good fit for the data.

```{r}
# Create a vector of the fitted values
Fitted1 <- fitted(BPRS_model1)
Fitted2 <- fitted(BPRS_model2)

# Create a new column fitted to BPRSL
BPRSL <- BPRSL %>% mutate(fitted1 = Fitted1, fitted2 = Fitted2)

# Draw the plot of BPRSL with the observed BPRS values
ggplot(BPRSL, aes(x = week, y = bprs, group = subject)) +
  geom_line(aes(linetype=subject)) + facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name= "Weeks") + scale_y_continuous(name = "BPRS points") + theme(legend.position = "top") +
  theme(legend.position = "none")

# Draw the plots of BPRSL with the Fitted values of BPRS (model 1)
ggplot(BPRSL, aes(x = week, y = fitted1, group = subject)) +
  geom_line(aes(linetype = subject)) + facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name = "Weeks") +
  scale_y_continuous(name = "Fitted BPRS points") +
  theme(legend.position = "none")

# Model 2
ggplot(BPRSL, aes(x = week, y = fitted2, group = subject)) +
  geom_line(aes(linetype = subject)) + facet_grid(. ~ treatment, labeller = label_both) +
  scale_x_continuous(name = "Weeks") +
  scale_y_continuous(name = "Fitted BPRS points") +
  theme(legend.position = "none")

```

The fitted plots are very similar to each other, so no help in that regard. What we do see is that the fitted values do okish at modelling our data. The fitted values are not good at handling outliers, so one subject randomly jumps up with their BPRS score and the subject with extreme BPRS scores has gone down compared to the actual values. 